{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício sobre pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize o dataset 'datasetCarros.csv'.<br>\n",
    "Usando Pytorch, construa uma rede neural para prever a feature 'PrecoVenda'.<br>\n",
    "\n",
    "Use uma rede neural feed forward com duas camadas escondidas, com 20 neurônios cada.<br>\n",
    "Use o critério de perda MSELoss, otimizador Adam e learning rate = 0.001. Considere 1000 épocas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T00:37:39.415293Z",
     "start_time": "2024-12-08T00:37:38.732868Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class Feedforward(torch.nn.Module):\n",
    "    \n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            \n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()\n",
    "            \n",
    "            \n",
    "        def forward(self, x):\n",
    "            output = self.fc1(x)\n",
    "            output = self.relu(output)\n",
    "            \n",
    "            output = self.fc2(output)\n",
    "            output = self.relu(output)\n",
    "            \n",
    "            output = self.fc3(output)\n",
    "\n",
    "            return output\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dfCarros = pd.read_csv('datasetCarros.csv')\n",
    "\n",
    "dfCarros.replace({'TipoCombustivel':{'Petrol':0,'Diesel':1,'CNG':2}},inplace=True)\n",
    "dfCarros.replace({'Trasmissao':{'Manual':0,'Automatic':1}},inplace=True)\n",
    "\n",
    "\n",
    "y= dfCarros['PrecoVenda']\n",
    "X = dfCarros.drop(['Nome','PrecoVenda'],axis=1)\n",
    "\n",
    "\n",
    "y_tensor = torch.tensor(y)\n",
    "X_tensor = torch.tensor(X.to_numpy())\n",
    "print(y_tensor.shape)\n",
    "print(X_tensor.shape)\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X_tensor, y_tensor, test_size = 0.10, random_state=5)\n",
    "\n",
    "print(X_treino.shape)\n",
    "print(y_treino.shape)\n",
    "\n",
    "X_treino = X_treino.float().to(device)\n",
    "y_treino = y_treino.float().to(device)\n",
    "\n",
    "X_teste = X_teste.float().to(device)\n",
    "y_teste = y_teste.float().to(device)\n",
    "\n",
    "\n",
    "model = Feedforward(6, 20).to(device)\n",
    "print(model)\n",
    "criterion = torch.nn.MSELoss() # Já usando MSELoss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001) # Já usando otimizador Adam e learning rate 0.001\n",
    "\n",
    "model.eval()\n",
    "y_pred = model(X_teste)\n",
    "antes_treino = criterion(y_pred, y_teste) \n",
    "print('Teste - perda antes do treinamento' , antes_treino.item())\n",
    "\n",
    "epoch = 1000 # Epochs ajustado para 1000 conforme requisitado\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Passe Forward\n",
    "    y_pred = model(X_treino)\n",
    "    \n",
    "    # Computa a perda\n",
    "    loss = criterion(y_pred, y_treino)\n",
    "    \n",
    "    print('Epoch {}: perda treino: {}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # Passe de Backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "model.eval()\n",
    "y_pred = model(X_teste)\n",
    "after_train = criterion(y_pred, y_teste) \n",
    "print('Teste - perda depois do treinamento' , after_train.item())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55632/542827987.py:36: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dfCarros.replace({'TipoCombustivel':{'Petrol':0,'Diesel':1,'CNG':2}},inplace=True)\n",
      "/tmp/ipykernel_55632/542827987.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dfCarros.replace({'Trasmissao':{'Manual':0,'Automatic':1}},inplace=True)\n",
      "/home/felipe/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([31])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/felipe/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([270])) that is different to the input size (torch.Size([270, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([301])\n",
      "torch.Size([301, 6])\n",
      "torch.Size([270, 6])\n",
      "torch.Size([270])\n",
      "Feedforward(\n",
      "  (fc1): Linear(in_features=6, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Teste - perda antes do treinamento 13306.9326171875\n",
      "Epoch 0: perda treino: 10157.9521484375\n",
      "Epoch 1: perda treino: 678.1747436523438\n",
      "Epoch 2: perda treino: 2337.34619140625\n",
      "Epoch 3: perda treino: 4842.212890625\n",
      "Epoch 4: perda treino: 3863.563232421875\n",
      "Epoch 5: perda treino: 1657.1981201171875\n",
      "Epoch 6: perda treino: 279.0615234375\n",
      "Epoch 7: perda treino: 380.79949951171875\n",
      "Epoch 8: perda treino: 1310.1243896484375\n",
      "Epoch 9: perda treino: 1943.1484375\n",
      "Epoch 10: perda treino: 1745.8819580078125\n",
      "Epoch 11: perda treino: 996.3392944335938\n",
      "Epoch 12: perda treino: 301.8628845214844\n",
      "Epoch 13: perda treino: 79.82647705078125\n",
      "Epoch 14: perda treino: 337.534423828125\n",
      "Epoch 15: perda treino: 748.8736572265625\n",
      "Epoch 16: perda treino: 949.6897583007812\n",
      "Epoch 17: perda treino: 808.236328125\n",
      "Epoch 18: perda treino: 459.5685729980469\n",
      "Epoch 19: perda treino: 155.3448028564453\n",
      "Epoch 20: perda treino: 73.3227310180664\n",
      "Epoch 21: perda treino: 209.9135284423828\n",
      "Epoch 22: perda treino: 409.2936706542969\n",
      "Epoch 23: perda treino: 497.7900695800781\n",
      "Epoch 24: perda treino: 414.0170593261719\n",
      "Epoch 25: perda treino: 233.58819580078125\n",
      "Epoch 26: perda treino: 89.99346923828125\n",
      "Epoch 27: perda treino: 68.67803955078125\n",
      "Epoch 28: perda treino: 152.73272705078125\n",
      "Epoch 29: perda treino: 250.44757080078125\n",
      "Epoch 30: perda treino: 275.70892333984375\n",
      "Epoch 31: perda treino: 212.51718139648438\n",
      "Epoch 32: perda treino: 115.91142272949219\n",
      "Epoch 33: perda treino: 58.71803283691406\n",
      "Epoch 34: perda treino: 72.02193450927734\n",
      "Epoch 35: perda treino: 126.83755493164062\n",
      "Epoch 36: perda treino: 165.90623474121094\n",
      "Epoch 37: perda treino: 154.0960693359375\n",
      "Epoch 38: perda treino: 104.34544372558594\n",
      "Epoch 39: perda treino: 59.32295608520508\n",
      "Epoch 40: perda treino: 51.3505744934082\n",
      "Epoch 41: perda treino: 76.49659729003906\n",
      "Epoch 42: perda treino: 103.3808364868164\n",
      "Epoch 43: perda treino: 104.5603256225586\n",
      "Epoch 44: perda treino: 79.92330932617188\n",
      "Epoch 45: perda treino: 52.45812225341797\n",
      "Epoch 46: perda treino: 44.34449768066406\n",
      "Epoch 47: perda treino: 57.180912017822266\n",
      "Epoch 48: perda treino: 73.19416809082031\n",
      "Epoch 49: perda treino: 74.78899383544922\n",
      "Epoch 50: perda treino: 60.849754333496094\n",
      "Epoch 51: perda treino: 45.36344909667969\n",
      "Epoch 52: perda treino: 41.671714782714844\n",
      "Epoch 53: perda treino: 49.70148468017578\n",
      "Epoch 54: perda treino: 58.14650344848633\n",
      "Epoch 55: perda treino: 57.28494644165039\n",
      "Epoch 56: perda treino: 48.29917526245117\n",
      "Epoch 57: perda treino: 40.46864700317383\n",
      "Epoch 58: perda treino: 40.42631149291992\n",
      "Epoch 59: perda treino: 45.86948013305664\n",
      "Epoch 60: perda treino: 49.353675842285156\n",
      "Epoch 61: perda treino: 46.772369384765625\n",
      "Epoch 62: perda treino: 41.0543327331543\n",
      "Epoch 63: perda treino: 37.96743392944336\n",
      "Epoch 64: perda treino: 39.58220672607422\n",
      "Epoch 65: perda treino: 42.67458724975586\n",
      "Epoch 66: perda treino: 43.024173736572266\n",
      "Epoch 67: perda treino: 40.115013122558594\n",
      "Epoch 68: perda treino: 37.082550048828125\n",
      "Epoch 69: perda treino: 36.69983673095703\n",
      "Epoch 70: perda treino: 38.39918899536133\n",
      "Epoch 71: perda treino: 39.423030853271484\n",
      "Epoch 72: perda treino: 38.276588439941406\n",
      "Epoch 73: perda treino: 36.17776107788086\n",
      "Epoch 74: perda treino: 35.234073638916016\n",
      "Epoch 75: perda treino: 35.905025482177734\n",
      "Epoch 76: perda treino: 36.75017166137695\n",
      "Epoch 77: perda treino: 36.39895248413086\n",
      "Epoch 78: perda treino: 35.12362289428711\n",
      "Epoch 79: perda treino: 34.24183654785156\n",
      "Epoch 80: perda treino: 34.4013786315918\n",
      "Epoch 81: perda treino: 34.9215202331543\n",
      "Epoch 82: perda treino: 34.829246520996094\n",
      "Epoch 83: perda treino: 34.064083099365234\n",
      "Epoch 84: perda treino: 33.395877838134766\n",
      "Epoch 85: perda treino: 33.35607147216797\n",
      "Epoch 86: perda treino: 33.62934112548828\n",
      "Epoch 87: perda treino: 33.584712982177734\n",
      "Epoch 88: perda treino: 33.098060607910156\n",
      "Epoch 89: perda treino: 32.62178421020508\n",
      "Epoch 90: perda treino: 32.55704879760742\n",
      "Epoch 91: perda treino: 32.71329116821289\n",
      "Epoch 92: perda treino: 32.67140579223633\n",
      "Epoch 93: perda treino: 32.34525680541992\n",
      "Epoch 94: perda treino: 32.0338134765625\n",
      "Epoch 95: perda treino: 31.96989631652832\n",
      "Epoch 96: perda treino: 32.03171920776367\n",
      "Epoch 97: perda treino: 31.960304260253906\n",
      "Epoch 98: perda treino: 31.72103500366211\n",
      "Epoch 99: perda treino: 31.51095962524414\n",
      "Epoch 100: perda treino: 31.45746612548828\n",
      "Epoch 101: perda treino: 31.462167739868164\n",
      "Epoch 102: perda treino: 31.37131690979004\n",
      "Epoch 103: perda treino: 31.189533233642578\n",
      "Epoch 104: perda treino: 31.046913146972656\n",
      "Epoch 105: perda treino: 31.00182342529297\n",
      "Epoch 106: perda treino: 30.97525978088379\n",
      "Epoch 107: perda treino: 30.880863189697266\n",
      "Epoch 108: perda treino: 30.7474422454834\n",
      "Epoch 109: perda treino: 30.653676986694336\n",
      "Epoch 110: perda treino: 30.611982345581055\n",
      "Epoch 111: perda treino: 30.563217163085938\n",
      "Epoch 112: perda treino: 30.473487854003906\n",
      "Epoch 113: perda treino: 30.376663208007812\n",
      "Epoch 114: perda treino: 30.31068992614746\n",
      "Epoch 115: perda treino: 30.266508102416992\n",
      "Epoch 116: perda treino: 30.209285736083984\n",
      "Epoch 117: perda treino: 30.13313865661621\n",
      "Epoch 118: perda treino: 30.06230354309082\n",
      "Epoch 119: perda treino: 30.012351989746094\n",
      "Epoch 120: perda treino: 29.96738052368164\n",
      "Epoch 121: perda treino: 29.904094696044922\n",
      "Epoch 122: perda treino: 29.83390235900879\n",
      "Epoch 123: perda treino: 29.773820877075195\n",
      "Epoch 124: perda treino: 29.724395751953125\n",
      "Epoch 125: perda treino: 29.671873092651367\n",
      "Epoch 126: perda treino: 29.61066436767578\n",
      "Epoch 127: perda treino: 29.549985885620117\n",
      "Epoch 128: perda treino: 29.498449325561523\n",
      "Epoch 129: perda treino: 29.451433181762695\n",
      "Epoch 130: perda treino: 29.39012336730957\n",
      "Epoch 131: perda treino: 29.31815528869629\n",
      "Epoch 132: perda treino: 29.245874404907227\n",
      "Epoch 133: perda treino: 29.17544937133789\n",
      "Epoch 134: perda treino: 29.104848861694336\n",
      "Epoch 135: perda treino: 29.021530151367188\n",
      "Epoch 136: perda treino: 28.934894561767578\n",
      "Epoch 137: perda treino: 28.851213455200195\n",
      "Epoch 138: perda treino: 28.769563674926758\n",
      "Epoch 139: perda treino: 28.687950134277344\n",
      "Epoch 140: perda treino: 28.608556747436523\n",
      "Epoch 141: perda treino: 28.53400230407715\n",
      "Epoch 142: perda treino: 28.464418411254883\n",
      "Epoch 143: perda treino: 28.397541046142578\n",
      "Epoch 144: perda treino: 28.332366943359375\n",
      "Epoch 145: perda treino: 28.2701473236084\n",
      "Epoch 146: perda treino: 28.21248435974121\n",
      "Epoch 147: perda treino: 28.157230377197266\n",
      "Epoch 148: perda treino: 28.102313995361328\n",
      "Epoch 149: perda treino: 28.049047470092773\n",
      "Epoch 150: perda treino: 27.997684478759766\n",
      "Epoch 151: perda treino: 27.947776794433594\n",
      "Epoch 152: perda treino: 27.898221969604492\n",
      "Epoch 153: perda treino: 27.84914779663086\n",
      "Epoch 154: perda treino: 27.80108070373535\n",
      "Epoch 155: perda treino: 27.75446128845215\n",
      "Epoch 156: perda treino: 27.709049224853516\n",
      "Epoch 157: perda treino: 27.6641902923584\n",
      "Epoch 158: perda treino: 27.620758056640625\n",
      "Epoch 159: perda treino: 27.57874298095703\n",
      "Epoch 160: perda treino: 27.538244247436523\n",
      "Epoch 161: perda treino: 27.499088287353516\n",
      "Epoch 162: perda treino: 27.461109161376953\n",
      "Epoch 163: perda treino: 27.424671173095703\n",
      "Epoch 164: perda treino: 27.389734268188477\n",
      "Epoch 165: perda treino: 27.355913162231445\n",
      "Epoch 166: perda treino: 27.323137283325195\n",
      "Epoch 167: perda treino: 27.28864288330078\n",
      "Epoch 168: perda treino: 27.250226974487305\n",
      "Epoch 169: perda treino: 27.21045684814453\n",
      "Epoch 170: perda treino: 27.169921875\n",
      "Epoch 171: perda treino: 27.128437042236328\n",
      "Epoch 172: perda treino: 27.08639907836914\n",
      "Epoch 173: perda treino: 27.044071197509766\n",
      "Epoch 174: perda treino: 27.002309799194336\n",
      "Epoch 175: perda treino: 26.961475372314453\n",
      "Epoch 176: perda treino: 26.921863555908203\n",
      "Epoch 177: perda treino: 26.883697509765625\n",
      "Epoch 178: perda treino: 26.847204208374023\n",
      "Epoch 179: perda treino: 26.8125\n",
      "Epoch 180: perda treino: 26.779436111450195\n",
      "Epoch 181: perda treino: 26.74797248840332\n",
      "Epoch 182: perda treino: 26.718164443969727\n",
      "Epoch 183: perda treino: 26.68986701965332\n",
      "Epoch 184: perda treino: 26.662813186645508\n",
      "Epoch 185: perda treino: 26.63690948486328\n",
      "Epoch 186: perda treino: 26.61212921142578\n",
      "Epoch 187: perda treino: 26.588289260864258\n",
      "Epoch 188: perda treino: 26.565292358398438\n",
      "Epoch 189: perda treino: 26.542936325073242\n",
      "Epoch 190: perda treino: 26.521310806274414\n",
      "Epoch 191: perda treino: 26.50037384033203\n",
      "Epoch 192: perda treino: 26.48006248474121\n",
      "Epoch 193: perda treino: 26.460315704345703\n",
      "Epoch 194: perda treino: 26.441261291503906\n",
      "Epoch 195: perda treino: 26.422893524169922\n",
      "Epoch 196: perda treino: 26.40518569946289\n",
      "Epoch 197: perda treino: 26.388219833374023\n",
      "Epoch 198: perda treino: 26.371875762939453\n",
      "Epoch 199: perda treino: 26.35614013671875\n",
      "Epoch 200: perda treino: 26.341075897216797\n",
      "Epoch 201: perda treino: 26.32668113708496\n",
      "Epoch 202: perda treino: 26.312938690185547\n",
      "Epoch 203: perda treino: 26.29977798461914\n",
      "Epoch 204: perda treino: 26.287254333496094\n",
      "Epoch 205: perda treino: 26.275297164916992\n",
      "Epoch 206: perda treino: 26.263893127441406\n",
      "Epoch 207: perda treino: 26.252939224243164\n",
      "Epoch 208: perda treino: 26.242454528808594\n",
      "Epoch 209: perda treino: 26.232376098632812\n",
      "Epoch 210: perda treino: 26.222715377807617\n",
      "Epoch 211: perda treino: 26.213396072387695\n",
      "Epoch 212: perda treino: 26.204235076904297\n",
      "Epoch 213: perda treino: 26.19534683227539\n",
      "Epoch 214: perda treino: 26.186738967895508\n",
      "Epoch 215: perda treino: 26.178394317626953\n",
      "Epoch 216: perda treino: 26.170331954956055\n",
      "Epoch 217: perda treino: 26.162555694580078\n",
      "Epoch 218: perda treino: 26.155006408691406\n",
      "Epoch 219: perda treino: 26.147737503051758\n",
      "Epoch 220: perda treino: 26.140708923339844\n",
      "Epoch 221: perda treino: 26.133935928344727\n",
      "Epoch 222: perda treino: 26.127395629882812\n",
      "Epoch 223: perda treino: 26.121084213256836\n",
      "Epoch 224: perda treino: 26.11502456665039\n",
      "Epoch 225: perda treino: 26.109169006347656\n",
      "Epoch 226: perda treino: 26.103525161743164\n",
      "Epoch 227: perda treino: 26.098079681396484\n",
      "Epoch 228: perda treino: 26.092819213867188\n",
      "Epoch 229: perda treino: 26.087751388549805\n",
      "Epoch 230: perda treino: 26.08283805847168\n",
      "Epoch 231: perda treino: 26.078079223632812\n",
      "Epoch 232: perda treino: 26.07347869873047\n",
      "Epoch 233: perda treino: 26.069002151489258\n",
      "Epoch 234: perda treino: 26.064666748046875\n",
      "Epoch 235: perda treino: 26.06048011779785\n",
      "Epoch 236: perda treino: 26.056419372558594\n",
      "Epoch 237: perda treino: 26.05246353149414\n",
      "Epoch 238: perda treino: 26.04861831665039\n",
      "Epoch 239: perda treino: 26.044879913330078\n",
      "Epoch 240: perda treino: 26.041236877441406\n",
      "Epoch 241: perda treino: 26.037677764892578\n",
      "Epoch 242: perda treino: 26.03420066833496\n",
      "Epoch 243: perda treino: 26.03080940246582\n",
      "Epoch 244: perda treino: 26.027496337890625\n",
      "Epoch 245: perda treino: 26.024250030517578\n",
      "Epoch 246: perda treino: 26.021068572998047\n",
      "Epoch 247: perda treino: 26.017953872680664\n",
      "Epoch 248: perda treino: 26.01490592956543\n",
      "Epoch 249: perda treino: 26.011911392211914\n",
      "Epoch 250: perda treino: 26.00896453857422\n",
      "Epoch 251: perda treino: 26.006078720092773\n",
      "Epoch 252: perda treino: 26.00324058532715\n",
      "Epoch 253: perda treino: 26.00045394897461\n",
      "Epoch 254: perda treino: 25.99770736694336\n",
      "Epoch 255: perda treino: 25.9950008392334\n",
      "Epoch 256: perda treino: 25.99234390258789\n",
      "Epoch 257: perda treino: 25.989721298217773\n",
      "Epoch 258: perda treino: 25.987136840820312\n",
      "Epoch 259: perda treino: 25.984588623046875\n",
      "Epoch 260: perda treino: 25.982078552246094\n",
      "Epoch 261: perda treino: 25.979602813720703\n",
      "Epoch 262: perda treino: 25.97715187072754\n",
      "Epoch 263: perda treino: 25.974733352661133\n",
      "Epoch 264: perda treino: 25.972349166870117\n",
      "Epoch 265: perda treino: 25.969999313354492\n",
      "Epoch 266: perda treino: 25.96766471862793\n",
      "Epoch 267: perda treino: 25.965373992919922\n",
      "Epoch 268: perda treino: 25.963088989257812\n",
      "Epoch 269: perda treino: 25.96084213256836\n",
      "Epoch 270: perda treino: 25.9586124420166\n",
      "Epoch 271: perda treino: 25.9564151763916\n",
      "Epoch 272: perda treino: 25.954238891601562\n",
      "Epoch 273: perda treino: 25.952070236206055\n",
      "Epoch 274: perda treino: 25.949939727783203\n",
      "Epoch 275: perda treino: 25.94781494140625\n",
      "Epoch 276: perda treino: 25.945724487304688\n",
      "Epoch 277: perda treino: 25.943641662597656\n",
      "Epoch 278: perda treino: 25.94158172607422\n",
      "Epoch 279: perda treino: 25.939544677734375\n",
      "Epoch 280: perda treino: 25.93752670288086\n",
      "Epoch 281: perda treino: 25.93551254272461\n",
      "Epoch 282: perda treino: 25.93352699279785\n",
      "Epoch 283: perda treino: 25.931549072265625\n",
      "Epoch 284: perda treino: 25.929597854614258\n",
      "Epoch 285: perda treino: 25.92764663696289\n",
      "Epoch 286: perda treino: 25.925724029541016\n",
      "Epoch 287: perda treino: 25.92380714416504\n",
      "Epoch 288: perda treino: 25.92191505432129\n",
      "Epoch 289: perda treino: 25.920032501220703\n",
      "Epoch 290: perda treino: 25.918155670166016\n",
      "Epoch 291: perda treino: 25.91630744934082\n",
      "Epoch 292: perda treino: 25.914457321166992\n",
      "Epoch 293: perda treino: 25.912626266479492\n",
      "Epoch 294: perda treino: 25.91080665588379\n",
      "Epoch 295: perda treino: 25.909006118774414\n",
      "Epoch 296: perda treino: 25.907207489013672\n",
      "Epoch 297: perda treino: 25.90543556213379\n",
      "Epoch 298: perda treino: 25.903671264648438\n",
      "Epoch 299: perda treino: 25.90191078186035\n",
      "Epoch 300: perda treino: 25.900165557861328\n",
      "Epoch 301: perda treino: 25.8984317779541\n",
      "Epoch 302: perda treino: 25.896705627441406\n",
      "Epoch 303: perda treino: 25.89499282836914\n",
      "Epoch 304: perda treino: 25.893291473388672\n",
      "Epoch 305: perda treino: 25.8916072845459\n",
      "Epoch 306: perda treino: 25.889921188354492\n",
      "Epoch 307: perda treino: 25.888261795043945\n",
      "Epoch 308: perda treino: 25.8866024017334\n",
      "Epoch 309: perda treino: 25.884952545166016\n",
      "Epoch 310: perda treino: 25.883325576782227\n",
      "Epoch 311: perda treino: 25.881694793701172\n",
      "Epoch 312: perda treino: 25.880081176757812\n",
      "Epoch 313: perda treino: 25.87847137451172\n",
      "Epoch 314: perda treino: 25.87687873840332\n",
      "Epoch 315: perda treino: 25.875293731689453\n",
      "Epoch 316: perda treino: 25.87371826171875\n",
      "Epoch 317: perda treino: 25.872146606445312\n",
      "Epoch 318: perda treino: 25.87058448791504\n",
      "Epoch 319: perda treino: 25.869037628173828\n",
      "Epoch 320: perda treino: 25.867496490478516\n",
      "Epoch 321: perda treino: 25.86598014831543\n",
      "Epoch 322: perda treino: 25.86445426940918\n",
      "Epoch 323: perda treino: 25.86294174194336\n",
      "Epoch 324: perda treino: 25.8614444732666\n",
      "Epoch 325: perda treino: 25.85995101928711\n",
      "Epoch 326: perda treino: 25.85846710205078\n",
      "Epoch 327: perda treino: 25.856998443603516\n",
      "Epoch 328: perda treino: 25.855527877807617\n",
      "Epoch 329: perda treino: 25.854074478149414\n",
      "Epoch 330: perda treino: 25.852630615234375\n",
      "Epoch 331: perda treino: 25.851181030273438\n",
      "Epoch 332: perda treino: 25.84975242614746\n",
      "Epoch 333: perda treino: 25.84834098815918\n",
      "Epoch 334: perda treino: 25.846914291381836\n",
      "Epoch 335: perda treino: 25.84551429748535\n",
      "Epoch 336: perda treino: 25.8441162109375\n",
      "Epoch 337: perda treino: 25.842723846435547\n",
      "Epoch 338: perda treino: 25.841337203979492\n",
      "Epoch 339: perda treino: 25.8399658203125\n",
      "Epoch 340: perda treino: 25.838603973388672\n",
      "Epoch 341: perda treino: 25.837244033813477\n",
      "Epoch 342: perda treino: 25.835899353027344\n",
      "Epoch 343: perda treino: 25.83455467224121\n",
      "Epoch 344: perda treino: 25.833223342895508\n",
      "Epoch 345: perda treino: 25.831897735595703\n",
      "Epoch 346: perda treino: 25.830570220947266\n",
      "Epoch 347: perda treino: 25.829269409179688\n",
      "Epoch 348: perda treino: 25.827966690063477\n",
      "Epoch 349: perda treino: 25.826669692993164\n",
      "Epoch 350: perda treino: 25.825380325317383\n",
      "Epoch 351: perda treino: 25.8240966796875\n",
      "Epoch 352: perda treino: 25.82282257080078\n",
      "Epoch 353: perda treino: 25.821556091308594\n",
      "Epoch 354: perda treino: 25.820289611816406\n",
      "Epoch 355: perda treino: 25.819046020507812\n",
      "Epoch 356: perda treino: 25.81780433654785\n",
      "Epoch 357: perda treino: 25.816560745239258\n",
      "Epoch 358: perda treino: 25.815322875976562\n",
      "Epoch 359: perda treino: 25.81410026550293\n",
      "Epoch 360: perda treino: 25.81287384033203\n",
      "Epoch 361: perda treino: 25.81166648864746\n",
      "Epoch 362: perda treino: 25.81045913696289\n",
      "Epoch 363: perda treino: 25.80925941467285\n",
      "Epoch 364: perda treino: 25.808069229125977\n",
      "Epoch 365: perda treino: 25.80687713623047\n",
      "Epoch 366: perda treino: 25.805700302124023\n",
      "Epoch 367: perda treino: 25.804523468017578\n",
      "Epoch 368: perda treino: 25.80335807800293\n",
      "Epoch 369: perda treino: 25.802194595336914\n",
      "Epoch 370: perda treino: 25.801034927368164\n",
      "Epoch 371: perda treino: 25.79988670349121\n",
      "Epoch 372: perda treino: 25.798742294311523\n",
      "Epoch 373: perda treino: 25.797605514526367\n",
      "Epoch 374: perda treino: 25.796466827392578\n",
      "Epoch 375: perda treino: 25.795345306396484\n",
      "Epoch 376: perda treino: 25.79422378540039\n",
      "Epoch 377: perda treino: 25.793109893798828\n",
      "Epoch 378: perda treino: 25.79199981689453\n",
      "Epoch 379: perda treino: 25.790891647338867\n",
      "Epoch 380: perda treino: 25.789796829223633\n",
      "Epoch 381: perda treino: 25.788700103759766\n",
      "Epoch 382: perda treino: 25.78761863708496\n",
      "Epoch 383: perda treino: 25.786537170410156\n",
      "Epoch 384: perda treino: 25.78545570373535\n",
      "Epoch 385: perda treino: 25.78438377380371\n",
      "Epoch 386: perda treino: 25.7833194732666\n",
      "Epoch 387: perda treino: 25.78226089477539\n",
      "Epoch 388: perda treino: 25.781198501586914\n",
      "Epoch 389: perda treino: 25.780155181884766\n",
      "Epoch 390: perda treino: 25.779104232788086\n",
      "Epoch 391: perda treino: 25.7780704498291\n",
      "Epoch 392: perda treino: 25.777055740356445\n",
      "Epoch 393: perda treino: 25.77603530883789\n",
      "Epoch 394: perda treino: 25.775001525878906\n",
      "Epoch 395: perda treino: 25.77399444580078\n",
      "Epoch 396: perda treino: 25.772994995117188\n",
      "Epoch 397: perda treino: 25.771989822387695\n",
      "Epoch 398: perda treino: 25.770994186401367\n",
      "Epoch 399: perda treino: 25.770002365112305\n",
      "Epoch 400: perda treino: 25.769004821777344\n",
      "Epoch 401: perda treino: 25.768028259277344\n",
      "Epoch 402: perda treino: 25.76704978942871\n",
      "Epoch 403: perda treino: 25.76607322692871\n",
      "Epoch 404: perda treino: 25.765098571777344\n",
      "Epoch 405: perda treino: 25.764142990112305\n",
      "Epoch 406: perda treino: 25.763179779052734\n",
      "Epoch 407: perda treino: 25.762229919433594\n",
      "Epoch 408: perda treino: 25.761276245117188\n",
      "Epoch 409: perda treino: 25.760332107543945\n",
      "Epoch 410: perda treino: 25.75938606262207\n",
      "Epoch 411: perda treino: 25.75845718383789\n",
      "Epoch 412: perda treino: 25.757516860961914\n",
      "Epoch 413: perda treino: 25.756589889526367\n",
      "Epoch 414: perda treino: 25.755664825439453\n",
      "Epoch 415: perda treino: 25.754743576049805\n",
      "Epoch 416: perda treino: 25.753828048706055\n",
      "Epoch 417: perda treino: 25.752918243408203\n",
      "Epoch 418: perda treino: 25.752016067504883\n",
      "Epoch 419: perda treino: 25.751108169555664\n",
      "Epoch 420: perda treino: 25.750205993652344\n",
      "Epoch 421: perda treino: 25.749313354492188\n",
      "Epoch 422: perda treino: 25.748422622680664\n",
      "Epoch 423: perda treino: 25.74753761291504\n",
      "Epoch 424: perda treino: 25.74664878845215\n",
      "Epoch 425: perda treino: 25.74576759338379\n",
      "Epoch 426: perda treino: 25.744897842407227\n",
      "Epoch 427: perda treino: 25.744028091430664\n",
      "Epoch 428: perda treino: 25.7431583404541\n",
      "Epoch 429: perda treino: 25.742298126220703\n",
      "Epoch 430: perda treino: 25.74143409729004\n",
      "Epoch 431: perda treino: 25.740575790405273\n",
      "Epoch 432: perda treino: 25.739728927612305\n",
      "Epoch 433: perda treino: 25.73887825012207\n",
      "Epoch 434: perda treino: 25.738035202026367\n",
      "Epoch 435: perda treino: 25.737192153930664\n",
      "Epoch 436: perda treino: 25.736356735229492\n",
      "Epoch 437: perda treino: 25.735523223876953\n",
      "Epoch 438: perda treino: 25.734695434570312\n",
      "Epoch 439: perda treino: 25.733867645263672\n",
      "Epoch 440: perda treino: 25.733047485351562\n",
      "Epoch 441: perda treino: 25.73223304748535\n",
      "Epoch 442: perda treino: 25.731412887573242\n",
      "Epoch 443: perda treino: 25.73060417175293\n",
      "Epoch 444: perda treino: 25.729793548583984\n",
      "Epoch 445: perda treino: 25.72899055480957\n",
      "Epoch 446: perda treino: 25.728195190429688\n",
      "Epoch 447: perda treino: 25.727397918701172\n",
      "Epoch 448: perda treino: 25.726604461669922\n",
      "Epoch 449: perda treino: 25.72581672668457\n",
      "Epoch 450: perda treino: 25.725025177001953\n",
      "Epoch 451: perda treino: 25.724245071411133\n",
      "Epoch 452: perda treino: 25.72347068786621\n",
      "Epoch 453: perda treino: 25.722692489624023\n",
      "Epoch 454: perda treino: 25.7219181060791\n",
      "Epoch 455: perda treino: 25.72115135192871\n",
      "Epoch 456: perda treino: 25.720386505126953\n",
      "Epoch 457: perda treino: 25.719629287719727\n",
      "Epoch 458: perda treino: 25.718868255615234\n",
      "Epoch 459: perda treino: 25.718114852905273\n",
      "Epoch 460: perda treino: 25.717365264892578\n",
      "Epoch 461: perda treino: 25.71661376953125\n",
      "Epoch 462: perda treino: 25.715869903564453\n",
      "Epoch 463: perda treino: 25.715129852294922\n",
      "Epoch 464: perda treino: 25.71439552307129\n",
      "Epoch 465: perda treino: 25.71365737915039\n",
      "Epoch 466: perda treino: 25.71292495727539\n",
      "Epoch 467: perda treino: 25.71219825744629\n",
      "Epoch 468: perda treino: 25.711477279663086\n",
      "Epoch 469: perda treino: 25.71075439453125\n",
      "Epoch 470: perda treino: 25.71003532409668\n",
      "Epoch 471: perda treino: 25.709320068359375\n",
      "Epoch 472: perda treino: 25.708606719970703\n",
      "Epoch 473: perda treino: 25.707904815673828\n",
      "Epoch 474: perda treino: 25.707199096679688\n",
      "Epoch 475: perda treino: 25.706499099731445\n",
      "Epoch 476: perda treino: 25.70580291748047\n",
      "Epoch 477: perda treino: 25.705108642578125\n",
      "Epoch 478: perda treino: 25.70441436767578\n",
      "Epoch 479: perda treino: 25.703725814819336\n",
      "Epoch 480: perda treino: 25.703039169311523\n",
      "Epoch 481: perda treino: 25.702356338500977\n",
      "Epoch 482: perda treino: 25.701677322387695\n",
      "Epoch 483: perda treino: 25.700998306274414\n",
      "Epoch 484: perda treino: 25.7003231048584\n",
      "Epoch 485: perda treino: 25.69965362548828\n",
      "Epoch 486: perda treino: 25.698991775512695\n",
      "Epoch 487: perda treino: 25.69832420349121\n",
      "Epoch 488: perda treino: 25.697664260864258\n",
      "Epoch 489: perda treino: 25.697006225585938\n",
      "Epoch 490: perda treino: 25.696353912353516\n",
      "Epoch 491: perda treino: 25.69569969177246\n",
      "Epoch 492: perda treino: 25.695049285888672\n",
      "Epoch 493: perda treino: 25.694406509399414\n",
      "Epoch 494: perda treino: 25.693761825561523\n",
      "Epoch 495: perda treino: 25.69312286376953\n",
      "Epoch 496: perda treino: 25.692485809326172\n",
      "Epoch 497: perda treino: 25.69185447692871\n",
      "Epoch 498: perda treino: 25.691225051879883\n",
      "Epoch 499: perda treino: 25.690593719482422\n",
      "Epoch 500: perda treino: 25.689970016479492\n",
      "Epoch 501: perda treino: 25.689348220825195\n",
      "Epoch 502: perda treino: 25.68872833251953\n",
      "Epoch 503: perda treino: 25.68811798095703\n",
      "Epoch 504: perda treino: 25.687503814697266\n",
      "Epoch 505: perda treino: 25.686893463134766\n",
      "Epoch 506: perda treino: 25.686290740966797\n",
      "Epoch 507: perda treino: 25.68568992614746\n",
      "Epoch 508: perda treino: 25.685096740722656\n",
      "Epoch 509: perda treino: 25.68450164794922\n",
      "Epoch 510: perda treino: 25.683908462524414\n",
      "Epoch 511: perda treino: 25.68332290649414\n",
      "Epoch 512: perda treino: 25.6827392578125\n",
      "Epoch 513: perda treino: 25.682157516479492\n",
      "Epoch 514: perda treino: 25.68157958984375\n",
      "Epoch 515: perda treino: 25.681001663208008\n",
      "Epoch 516: perda treino: 25.680431365966797\n",
      "Epoch 517: perda treino: 25.679859161376953\n",
      "Epoch 518: perda treino: 25.67928695678711\n",
      "Epoch 519: perda treino: 25.67872428894043\n",
      "Epoch 520: perda treino: 25.678157806396484\n",
      "Epoch 521: perda treino: 25.677602767944336\n",
      "Epoch 522: perda treino: 25.677043914794922\n",
      "Epoch 523: perda treino: 25.676488876342773\n",
      "Epoch 524: perda treino: 25.675935745239258\n",
      "Epoch 525: perda treino: 25.675390243530273\n",
      "Epoch 526: perda treino: 25.67483901977539\n",
      "Epoch 527: perda treino: 25.674297332763672\n",
      "Epoch 528: perda treino: 25.673757553100586\n",
      "Epoch 529: perda treino: 25.6732177734375\n",
      "Epoch 530: perda treino: 25.672683715820312\n",
      "Epoch 531: perda treino: 25.672149658203125\n",
      "Epoch 532: perda treino: 25.671621322631836\n",
      "Epoch 533: perda treino: 25.671092987060547\n",
      "Epoch 534: perda treino: 25.670568466186523\n",
      "Epoch 535: perda treino: 25.6700439453125\n",
      "Epoch 536: perda treino: 25.669523239135742\n",
      "Epoch 537: perda treino: 25.669004440307617\n",
      "Epoch 538: perda treino: 25.668487548828125\n",
      "Epoch 539: perda treino: 25.6679744720459\n",
      "Epoch 540: perda treino: 25.667463302612305\n",
      "Epoch 541: perda treino: 25.666955947875977\n",
      "Epoch 542: perda treino: 25.66644859313965\n",
      "Epoch 543: perda treino: 25.665943145751953\n",
      "Epoch 544: perda treino: 25.665443420410156\n",
      "Epoch 545: perda treino: 25.664947509765625\n",
      "Epoch 546: perda treino: 25.664453506469727\n",
      "Epoch 547: perda treino: 25.663959503173828\n",
      "Epoch 548: perda treino: 25.663467407226562\n",
      "Epoch 549: perda treino: 25.66297721862793\n",
      "Epoch 550: perda treino: 25.66248893737793\n",
      "Epoch 551: perda treino: 25.662006378173828\n",
      "Epoch 552: perda treino: 25.661529541015625\n",
      "Epoch 553: perda treino: 25.66104507446289\n",
      "Epoch 554: perda treino: 25.660568237304688\n",
      "Epoch 555: perda treino: 25.66009521484375\n",
      "Epoch 556: perda treino: 25.659622192382812\n",
      "Epoch 557: perda treino: 25.659149169921875\n",
      "Epoch 558: perda treino: 25.658679962158203\n",
      "Epoch 559: perda treino: 25.658214569091797\n",
      "Epoch 560: perda treino: 25.657751083374023\n",
      "Epoch 561: perda treino: 25.657291412353516\n",
      "Epoch 562: perda treino: 25.656835556030273\n",
      "Epoch 563: perda treino: 25.656375885009766\n",
      "Epoch 564: perda treino: 25.655921936035156\n",
      "Epoch 565: perda treino: 25.655473709106445\n",
      "Epoch 566: perda treino: 25.6550235748291\n",
      "Epoch 567: perda treino: 25.65457534790039\n",
      "Epoch 568: perda treino: 25.654129028320312\n",
      "Epoch 569: perda treino: 25.653684616088867\n",
      "Epoch 570: perda treino: 25.65324592590332\n",
      "Epoch 571: perda treino: 25.652807235717773\n",
      "Epoch 572: perda treino: 25.65237045288086\n",
      "Epoch 573: perda treino: 25.65193748474121\n",
      "Epoch 574: perda treino: 25.65150260925293\n",
      "Epoch 575: perda treino: 25.651073455810547\n",
      "Epoch 576: perda treino: 25.650644302368164\n",
      "Epoch 577: perda treino: 25.650218963623047\n",
      "Epoch 578: perda treino: 25.649795532226562\n",
      "Epoch 579: perda treino: 25.649375915527344\n",
      "Epoch 580: perda treino: 25.648954391479492\n",
      "Epoch 581: perda treino: 25.648536682128906\n",
      "Epoch 582: perda treino: 25.648120880126953\n",
      "Epoch 583: perda treino: 25.647708892822266\n",
      "Epoch 584: perda treino: 25.647300720214844\n",
      "Epoch 585: perda treino: 25.646888732910156\n",
      "Epoch 586: perda treino: 25.646484375\n",
      "Epoch 587: perda treino: 25.646076202392578\n",
      "Epoch 588: perda treino: 25.645675659179688\n",
      "Epoch 589: perda treino: 25.64527130126953\n",
      "Epoch 590: perda treino: 25.644872665405273\n",
      "Epoch 591: perda treino: 25.64447593688965\n",
      "Epoch 592: perda treino: 25.644081115722656\n",
      "Epoch 593: perda treino: 25.64369010925293\n",
      "Epoch 594: perda treino: 25.643299102783203\n",
      "Epoch 595: perda treino: 25.642911911010742\n",
      "Epoch 596: perda treino: 25.64252471923828\n",
      "Epoch 597: perda treino: 25.64213752746582\n",
      "Epoch 598: perda treino: 25.64175796508789\n",
      "Epoch 599: perda treino: 25.64137840270996\n",
      "Epoch 600: perda treino: 25.6409969329834\n",
      "Epoch 601: perda treino: 25.64061737060547\n",
      "Epoch 602: perda treino: 25.640243530273438\n",
      "Epoch 603: perda treino: 25.639869689941406\n",
      "Epoch 604: perda treino: 25.63949966430664\n",
      "Epoch 605: perda treino: 25.639131546020508\n",
      "Epoch 606: perda treino: 25.638765335083008\n",
      "Epoch 607: perda treino: 25.638399124145508\n",
      "Epoch 608: perda treino: 25.638036727905273\n",
      "Epoch 609: perda treino: 25.637672424316406\n",
      "Epoch 610: perda treino: 25.637311935424805\n",
      "Epoch 611: perda treino: 25.6369571685791\n",
      "Epoch 612: perda treino: 25.6366024017334\n",
      "Epoch 613: perda treino: 25.636240005493164\n",
      "Epoch 614: perda treino: 25.63589096069336\n",
      "Epoch 615: perda treino: 25.635541915893555\n",
      "Epoch 616: perda treino: 25.635190963745117\n",
      "Epoch 617: perda treino: 25.634845733642578\n",
      "Epoch 618: perda treino: 25.634498596191406\n",
      "Epoch 619: perda treino: 25.634153366088867\n",
      "Epoch 620: perda treino: 25.633813858032227\n",
      "Epoch 621: perda treino: 25.633474349975586\n",
      "Epoch 622: perda treino: 25.63313865661621\n",
      "Epoch 623: perda treino: 25.632801055908203\n",
      "Epoch 624: perda treino: 25.632465362548828\n",
      "Epoch 625: perda treino: 25.63213539123535\n",
      "Epoch 626: perda treino: 25.631803512573242\n",
      "Epoch 627: perda treino: 25.631473541259766\n",
      "Epoch 628: perda treino: 25.631147384643555\n",
      "Epoch 629: perda treino: 25.630821228027344\n",
      "Epoch 630: perda treino: 25.6304931640625\n",
      "Epoch 631: perda treino: 25.630170822143555\n",
      "Epoch 632: perda treino: 25.629852294921875\n",
      "Epoch 633: perda treino: 25.629533767700195\n",
      "Epoch 634: perda treino: 25.629215240478516\n",
      "Epoch 635: perda treino: 25.62889862060547\n",
      "Epoch 636: perda treino: 25.628583908081055\n",
      "Epoch 637: perda treino: 25.62827491760254\n",
      "Epoch 638: perda treino: 25.627962112426758\n",
      "Epoch 639: perda treino: 25.62765121459961\n",
      "Epoch 640: perda treino: 25.62734603881836\n",
      "Epoch 641: perda treino: 25.62704086303711\n",
      "Epoch 642: perda treino: 25.626737594604492\n",
      "Epoch 643: perda treino: 25.626434326171875\n",
      "Epoch 644: perda treino: 25.62613296508789\n",
      "Epoch 645: perda treino: 25.62583351135254\n",
      "Epoch 646: perda treino: 25.62553596496582\n",
      "Epoch 647: perda treino: 25.625240325927734\n",
      "Epoch 648: perda treino: 25.62494468688965\n",
      "Epoch 649: perda treino: 25.624652862548828\n",
      "Epoch 650: perda treino: 25.624361038208008\n",
      "Epoch 651: perda treino: 25.62407112121582\n",
      "Epoch 652: perda treino: 25.6237850189209\n",
      "Epoch 653: perda treino: 25.623497009277344\n",
      "Epoch 654: perda treino: 25.623212814331055\n",
      "Epoch 655: perda treino: 25.622928619384766\n",
      "Epoch 656: perda treino: 25.622648239135742\n",
      "Epoch 657: perda treino: 25.622365951538086\n",
      "Epoch 658: perda treino: 25.622085571289062\n",
      "Epoch 659: perda treino: 25.621809005737305\n",
      "Epoch 660: perda treino: 25.621532440185547\n",
      "Epoch 661: perda treino: 25.62125587463379\n",
      "Epoch 662: perda treino: 25.620981216430664\n",
      "Epoch 663: perda treino: 25.620710372924805\n",
      "Epoch 664: perda treino: 25.620441436767578\n",
      "Epoch 665: perda treino: 25.62017059326172\n",
      "Epoch 666: perda treino: 25.619903564453125\n",
      "Epoch 667: perda treino: 25.619638442993164\n",
      "Epoch 668: perda treino: 25.619373321533203\n",
      "Epoch 669: perda treino: 25.619112014770508\n",
      "Epoch 670: perda treino: 25.61884880065918\n",
      "Epoch 671: perda treino: 25.618589401245117\n",
      "Epoch 672: perda treino: 25.618330001831055\n",
      "Epoch 673: perda treino: 25.618072509765625\n",
      "Epoch 674: perda treino: 25.61781883239746\n",
      "Epoch 675: perda treino: 25.61756134033203\n",
      "Epoch 676: perda treino: 25.6173095703125\n",
      "Epoch 677: perda treino: 25.61705780029297\n",
      "Epoch 678: perda treino: 25.61680793762207\n",
      "Epoch 679: perda treino: 25.616558074951172\n",
      "Epoch 680: perda treino: 25.616308212280273\n",
      "Epoch 681: perda treino: 25.61606216430664\n",
      "Epoch 682: perda treino: 25.615819931030273\n",
      "Epoch 683: perda treino: 25.61557388305664\n",
      "Epoch 684: perda treino: 25.615331649780273\n",
      "Epoch 685: perda treino: 25.615089416503906\n",
      "Epoch 686: perda treino: 25.614849090576172\n",
      "Epoch 687: perda treino: 25.61461067199707\n",
      "Epoch 688: perda treino: 25.6143741607666\n",
      "Epoch 689: perda treino: 25.614139556884766\n",
      "Epoch 690: perda treino: 25.613903045654297\n",
      "Epoch 691: perda treino: 25.61366844177246\n",
      "Epoch 692: perda treino: 25.61343765258789\n",
      "Epoch 693: perda treino: 25.61320686340332\n",
      "Epoch 694: perda treino: 25.61297607421875\n",
      "Epoch 695: perda treino: 25.612751007080078\n",
      "Epoch 696: perda treino: 25.612524032592773\n",
      "Epoch 697: perda treino: 25.61229705810547\n",
      "Epoch 698: perda treino: 25.61207389831543\n",
      "Epoch 699: perda treino: 25.61185073852539\n",
      "Epoch 700: perda treino: 25.611629486083984\n",
      "Epoch 701: perda treino: 25.611408233642578\n",
      "Epoch 702: perda treino: 25.611188888549805\n",
      "Epoch 703: perda treino: 25.61096954345703\n",
      "Epoch 704: perda treino: 25.610754013061523\n",
      "Epoch 705: perda treino: 25.610538482666016\n",
      "Epoch 706: perda treino: 25.610294342041016\n",
      "Epoch 707: perda treino: 25.610034942626953\n",
      "Epoch 708: perda treino: 25.609766006469727\n",
      "Epoch 709: perda treino: 25.60948944091797\n",
      "Epoch 710: perda treino: 25.609207153320312\n",
      "Epoch 711: perda treino: 25.608924865722656\n",
      "Epoch 712: perda treino: 25.608642578125\n",
      "Epoch 713: perda treino: 25.608360290527344\n",
      "Epoch 714: perda treino: 25.608083724975586\n",
      "Epoch 715: perda treino: 25.607812881469727\n",
      "Epoch 716: perda treino: 25.6075439453125\n",
      "Epoch 717: perda treino: 25.607280731201172\n",
      "Epoch 718: perda treino: 25.607019424438477\n",
      "Epoch 719: perda treino: 25.60676383972168\n",
      "Epoch 720: perda treino: 25.606508255004883\n",
      "Epoch 721: perda treino: 25.60626220703125\n",
      "Epoch 722: perda treino: 25.60601043701172\n",
      "Epoch 723: perda treino: 25.605764389038086\n",
      "Epoch 724: perda treino: 25.605514526367188\n",
      "Epoch 725: perda treino: 25.605266571044922\n",
      "Epoch 726: perda treino: 25.60502052307129\n",
      "Epoch 727: perda treino: 25.604774475097656\n",
      "Epoch 728: perda treino: 25.60452651977539\n",
      "Epoch 729: perda treino: 25.60428237915039\n",
      "Epoch 730: perda treino: 25.604036331176758\n",
      "Epoch 731: perda treino: 25.603796005249023\n",
      "Epoch 732: perda treino: 25.60355567932129\n",
      "Epoch 733: perda treino: 25.603317260742188\n",
      "Epoch 734: perda treino: 25.603078842163086\n",
      "Epoch 735: perda treino: 25.602842330932617\n",
      "Epoch 736: perda treino: 25.60261344909668\n",
      "Epoch 737: perda treino: 25.60238265991211\n",
      "Epoch 738: perda treino: 25.602153778076172\n",
      "Epoch 739: perda treino: 25.6019287109375\n",
      "Epoch 740: perda treino: 25.60170555114746\n",
      "Epoch 741: perda treino: 25.601484298706055\n",
      "Epoch 742: perda treino: 25.60126495361328\n",
      "Epoch 743: perda treino: 25.601051330566406\n",
      "Epoch 744: perda treino: 25.6008358001709\n",
      "Epoch 745: perda treino: 25.600622177124023\n",
      "Epoch 746: perda treino: 25.600412368774414\n",
      "Epoch 747: perda treino: 25.600204467773438\n",
      "Epoch 748: perda treino: 25.599994659423828\n",
      "Epoch 749: perda treino: 25.599790573120117\n",
      "Epoch 750: perda treino: 25.599586486816406\n",
      "Epoch 751: perda treino: 25.599382400512695\n",
      "Epoch 752: perda treino: 25.59918212890625\n",
      "Epoch 753: perda treino: 25.59898567199707\n",
      "Epoch 754: perda treino: 25.598783493041992\n",
      "Epoch 755: perda treino: 25.598590850830078\n",
      "Epoch 756: perda treino: 25.59839630126953\n",
      "Epoch 757: perda treino: 25.598203659057617\n",
      "Epoch 758: perda treino: 25.598012924194336\n",
      "Epoch 759: perda treino: 25.597824096679688\n",
      "Epoch 760: perda treino: 25.597637176513672\n",
      "Epoch 761: perda treino: 25.59745216369629\n",
      "Epoch 762: perda treino: 25.597267150878906\n",
      "Epoch 763: perda treino: 25.597084045410156\n",
      "Epoch 764: perda treino: 25.59690284729004\n",
      "Epoch 765: perda treino: 25.596721649169922\n",
      "Epoch 766: perda treino: 25.596542358398438\n",
      "Epoch 767: perda treino: 25.59636878967285\n",
      "Epoch 768: perda treino: 25.596193313598633\n",
      "Epoch 769: perda treino: 25.596017837524414\n",
      "Epoch 770: perda treino: 25.59584617614746\n",
      "Epoch 771: perda treino: 25.59567642211914\n",
      "Epoch 772: perda treino: 25.595504760742188\n",
      "Epoch 773: perda treino: 25.5953369140625\n",
      "Epoch 774: perda treino: 25.59516716003418\n",
      "Epoch 775: perda treino: 25.594999313354492\n",
      "Epoch 776: perda treino: 25.59483528137207\n",
      "Epoch 777: perda treino: 25.594675064086914\n",
      "Epoch 778: perda treino: 25.594512939453125\n",
      "Epoch 779: perda treino: 25.59435272216797\n",
      "Epoch 780: perda treino: 25.594192504882812\n",
      "Epoch 781: perda treino: 25.594032287597656\n",
      "Epoch 782: perda treino: 25.593875885009766\n",
      "Epoch 783: perda treino: 25.593721389770508\n",
      "Epoch 784: perda treino: 25.593563079833984\n",
      "Epoch 785: perda treino: 25.593408584594727\n",
      "Epoch 786: perda treino: 25.593257904052734\n",
      "Epoch 787: perda treino: 25.593107223510742\n",
      "Epoch 788: perda treino: 25.592954635620117\n",
      "Epoch 789: perda treino: 25.59280776977539\n",
      "Epoch 790: perda treino: 25.5926570892334\n",
      "Epoch 791: perda treino: 25.592510223388672\n",
      "Epoch 792: perda treino: 25.592365264892578\n",
      "Epoch 793: perda treino: 25.59221839904785\n",
      "Epoch 794: perda treino: 25.59207534790039\n",
      "Epoch 795: perda treino: 25.591930389404297\n",
      "Epoch 796: perda treino: 25.59178924560547\n",
      "Epoch 797: perda treino: 25.591650009155273\n",
      "Epoch 798: perda treino: 25.591508865356445\n",
      "Epoch 799: perda treino: 25.59136962890625\n",
      "Epoch 800: perda treino: 25.591230392456055\n",
      "Epoch 801: perda treino: 25.591093063354492\n",
      "Epoch 802: perda treino: 25.590959548950195\n",
      "Epoch 803: perda treino: 25.590822219848633\n",
      "Epoch 804: perda treino: 25.590688705444336\n",
      "Epoch 805: perda treino: 25.59055519104004\n",
      "Epoch 806: perda treino: 25.590423583984375\n",
      "Epoch 807: perda treino: 25.590293884277344\n",
      "Epoch 808: perda treino: 25.590160369873047\n",
      "Epoch 809: perda treino: 25.59003257751465\n",
      "Epoch 810: perda treino: 25.58990478515625\n",
      "Epoch 811: perda treino: 25.58977699279785\n",
      "Epoch 812: perda treino: 25.589649200439453\n",
      "Epoch 813: perda treino: 25.589523315429688\n",
      "Epoch 814: perda treino: 25.589397430419922\n",
      "Epoch 815: perda treino: 25.58927345275879\n",
      "Epoch 816: perda treino: 25.589149475097656\n",
      "Epoch 817: perda treino: 25.589027404785156\n",
      "Epoch 818: perda treino: 25.588905334472656\n",
      "Epoch 819: perda treino: 25.588783264160156\n",
      "Epoch 820: perda treino: 25.58866310119629\n",
      "Epoch 821: perda treino: 25.588544845581055\n",
      "Epoch 822: perda treino: 25.58842658996582\n",
      "Epoch 823: perda treino: 25.588308334350586\n",
      "Epoch 824: perda treino: 25.588191986083984\n",
      "Epoch 825: perda treino: 25.588075637817383\n",
      "Epoch 826: perda treino: 25.58795928955078\n",
      "Epoch 827: perda treino: 25.587844848632812\n",
      "Epoch 828: perda treino: 25.587730407714844\n",
      "Epoch 829: perda treino: 25.587615966796875\n",
      "Epoch 830: perda treino: 25.587505340576172\n",
      "Epoch 831: perda treino: 25.587392807006836\n",
      "Epoch 832: perda treino: 25.587282180786133\n",
      "Epoch 833: perda treino: 25.58717155456543\n",
      "Epoch 834: perda treino: 25.587060928344727\n",
      "Epoch 835: perda treino: 25.586952209472656\n",
      "Epoch 836: perda treino: 25.58684539794922\n",
      "Epoch 837: perda treino: 25.58673858642578\n",
      "Epoch 838: perda treino: 25.58662986755371\n",
      "Epoch 839: perda treino: 25.58652687072754\n",
      "Epoch 840: perda treino: 25.5864200592041\n",
      "Epoch 841: perda treino: 25.586315155029297\n",
      "Epoch 842: perda treino: 25.586210250854492\n",
      "Epoch 843: perda treino: 25.58610725402832\n",
      "Epoch 844: perda treino: 25.58600425720215\n",
      "Epoch 845: perda treino: 25.585901260375977\n",
      "Epoch 846: perda treino: 25.585800170898438\n",
      "Epoch 847: perda treino: 25.5856990814209\n",
      "Epoch 848: perda treino: 25.585599899291992\n",
      "Epoch 849: perda treino: 25.585498809814453\n",
      "Epoch 850: perda treino: 25.58540153503418\n",
      "Epoch 851: perda treino: 25.585302352905273\n",
      "Epoch 852: perda treino: 25.585205078125\n",
      "Epoch 853: perda treino: 25.58510971069336\n",
      "Epoch 854: perda treino: 25.585012435913086\n",
      "Epoch 855: perda treino: 25.584917068481445\n",
      "Epoch 856: perda treino: 25.584821701049805\n",
      "Epoch 857: perda treino: 25.584726333618164\n",
      "Epoch 858: perda treino: 25.584632873535156\n",
      "Epoch 859: perda treino: 25.58454132080078\n",
      "Epoch 860: perda treino: 25.584447860717773\n",
      "Epoch 861: perda treino: 25.584354400634766\n",
      "Epoch 862: perda treino: 25.584264755249023\n",
      "Epoch 863: perda treino: 25.58417320251465\n",
      "Epoch 864: perda treino: 25.584083557128906\n",
      "Epoch 865: perda treino: 25.583993911743164\n",
      "Epoch 866: perda treino: 25.58390235900879\n",
      "Epoch 867: perda treino: 25.58381462097168\n",
      "Epoch 868: perda treino: 25.58372688293457\n",
      "Epoch 869: perda treino: 25.583641052246094\n",
      "Epoch 870: perda treino: 25.583555221557617\n",
      "Epoch 871: perda treino: 25.583467483520508\n",
      "Epoch 872: perda treino: 25.58338165283203\n",
      "Epoch 873: perda treino: 25.583297729492188\n",
      "Epoch 874: perda treino: 25.583213806152344\n",
      "Epoch 875: perda treino: 25.583127975463867\n",
      "Epoch 876: perda treino: 25.583044052124023\n",
      "Epoch 877: perda treino: 25.582962036132812\n",
      "Epoch 878: perda treino: 25.58287811279297\n",
      "Epoch 879: perda treino: 25.58279800415039\n",
      "Epoch 880: perda treino: 25.582717895507812\n",
      "Epoch 881: perda treino: 25.582637786865234\n",
      "Epoch 882: perda treino: 25.582557678222656\n",
      "Epoch 883: perda treino: 25.582475662231445\n",
      "Epoch 884: perda treino: 25.582399368286133\n",
      "Epoch 885: perda treino: 25.582317352294922\n",
      "Epoch 886: perda treino: 25.582239151000977\n",
      "Epoch 887: perda treino: 25.582164764404297\n",
      "Epoch 888: perda treino: 25.58208465576172\n",
      "Epoch 889: perda treino: 25.58201026916504\n",
      "Epoch 890: perda treino: 25.581933975219727\n",
      "Epoch 891: perda treino: 25.581859588623047\n",
      "Epoch 892: perda treino: 25.581785202026367\n",
      "Epoch 893: perda treino: 25.581708908081055\n",
      "Epoch 894: perda treino: 25.581636428833008\n",
      "Epoch 895: perda treino: 25.581562042236328\n",
      "Epoch 896: perda treino: 25.58148765563965\n",
      "Epoch 897: perda treino: 25.581417083740234\n",
      "Epoch 898: perda treino: 25.581344604492188\n",
      "Epoch 899: perda treino: 25.58127212524414\n",
      "Epoch 900: perda treino: 25.581201553344727\n",
      "Epoch 901: perda treino: 25.58112907409668\n",
      "Epoch 902: perda treino: 25.5810604095459\n",
      "Epoch 903: perda treino: 25.580991744995117\n",
      "Epoch 904: perda treino: 25.580921173095703\n",
      "Epoch 905: perda treino: 25.58085060119629\n",
      "Epoch 906: perda treino: 25.580781936645508\n",
      "Epoch 907: perda treino: 25.58071517944336\n",
      "Epoch 908: perda treino: 25.58064842224121\n",
      "Epoch 909: perda treino: 25.580581665039062\n",
      "Epoch 910: perda treino: 25.58051300048828\n",
      "Epoch 911: perda treino: 25.580448150634766\n",
      "Epoch 912: perda treino: 25.580381393432617\n",
      "Epoch 913: perda treino: 25.58031463623047\n",
      "Epoch 914: perda treino: 25.580249786376953\n",
      "Epoch 915: perda treino: 25.580184936523438\n",
      "Epoch 916: perda treino: 25.580120086669922\n",
      "Epoch 917: perda treino: 25.580055236816406\n",
      "Epoch 918: perda treino: 25.579992294311523\n",
      "Epoch 919: perda treino: 25.579927444458008\n",
      "Epoch 920: perda treino: 25.579866409301758\n",
      "Epoch 921: perda treino: 25.579805374145508\n",
      "Epoch 922: perda treino: 25.579742431640625\n",
      "Epoch 923: perda treino: 25.579679489135742\n",
      "Epoch 924: perda treino: 25.579618453979492\n",
      "Epoch 925: perda treino: 25.579557418823242\n",
      "Epoch 926: perda treino: 25.579496383666992\n",
      "Epoch 927: perda treino: 25.579435348510742\n",
      "Epoch 928: perda treino: 25.579376220703125\n",
      "Epoch 929: perda treino: 25.579317092895508\n",
      "Epoch 930: perda treino: 25.57925796508789\n",
      "Epoch 931: perda treino: 25.579198837280273\n",
      "Epoch 932: perda treino: 25.57914161682129\n",
      "Epoch 933: perda treino: 25.57908058166504\n",
      "Epoch 934: perda treino: 25.579023361206055\n",
      "Epoch 935: perda treino: 25.578968048095703\n",
      "Epoch 936: perda treino: 25.578908920288086\n",
      "Epoch 937: perda treino: 25.578853607177734\n",
      "Epoch 938: perda treino: 25.57879638671875\n",
      "Epoch 939: perda treino: 25.5787410736084\n",
      "Epoch 940: perda treino: 25.578683853149414\n",
      "Epoch 941: perda treino: 25.578630447387695\n",
      "Epoch 942: perda treino: 25.578575134277344\n",
      "Epoch 943: perda treino: 25.57851791381836\n",
      "Epoch 944: perda treino: 25.57846450805664\n",
      "Epoch 945: perda treino: 25.578413009643555\n",
      "Epoch 946: perda treino: 25.578357696533203\n",
      "Epoch 947: perda treino: 25.578304290771484\n",
      "Epoch 948: perda treino: 25.578250885009766\n",
      "Epoch 949: perda treino: 25.57819938659668\n",
      "Epoch 950: perda treino: 25.57814598083496\n",
      "Epoch 951: perda treino: 25.578092575073242\n",
      "Epoch 952: perda treino: 25.578041076660156\n",
      "Epoch 953: perda treino: 25.57798957824707\n",
      "Epoch 954: perda treino: 25.577938079833984\n",
      "Epoch 955: perda treino: 25.57788848876953\n",
      "Epoch 956: perda treino: 25.577838897705078\n",
      "Epoch 957: perda treino: 25.577787399291992\n",
      "Epoch 958: perda treino: 25.57773780822754\n",
      "Epoch 959: perda treino: 25.577688217163086\n",
      "Epoch 960: perda treino: 25.577638626098633\n",
      "Epoch 961: perda treino: 25.577590942382812\n",
      "Epoch 962: perda treino: 25.57754135131836\n",
      "Epoch 963: perda treino: 25.57749366760254\n",
      "Epoch 964: perda treino: 25.57744598388672\n",
      "Epoch 965: perda treino: 25.577396392822266\n",
      "Epoch 966: perda treino: 25.577348709106445\n",
      "Epoch 967: perda treino: 25.577302932739258\n",
      "Epoch 968: perda treino: 25.57725715637207\n",
      "Epoch 969: perda treino: 25.577207565307617\n",
      "Epoch 970: perda treino: 25.57716178894043\n",
      "Epoch 971: perda treino: 25.577116012573242\n",
      "Epoch 972: perda treino: 25.577070236206055\n",
      "Epoch 973: perda treino: 25.577024459838867\n",
      "Epoch 974: perda treino: 25.57697868347168\n",
      "Epoch 975: perda treino: 25.576934814453125\n",
      "Epoch 976: perda treino: 25.576889038085938\n",
      "Epoch 977: perda treino: 25.576845169067383\n",
      "Epoch 978: perda treino: 25.576801300048828\n",
      "Epoch 979: perda treino: 25.57675552368164\n",
      "Epoch 980: perda treino: 25.57671546936035\n",
      "Epoch 981: perda treino: 25.576669692993164\n",
      "Epoch 982: perda treino: 25.57662582397461\n",
      "Epoch 983: perda treino: 25.576583862304688\n",
      "Epoch 984: perda treino: 25.576541900634766\n",
      "Epoch 985: perda treino: 25.57649803161621\n",
      "Epoch 986: perda treino: 25.576457977294922\n",
      "Epoch 987: perda treino: 25.576412200927734\n",
      "Epoch 988: perda treino: 25.576372146606445\n",
      "Epoch 989: perda treino: 25.576330184936523\n",
      "Epoch 990: perda treino: 25.576290130615234\n",
      "Epoch 991: perda treino: 25.576248168945312\n",
      "Epoch 992: perda treino: 25.57620620727539\n",
      "Epoch 993: perda treino: 25.576169967651367\n",
      "Epoch 994: perda treino: 25.576128005981445\n",
      "Epoch 995: perda treino: 25.576087951660156\n",
      "Epoch 996: perda treino: 25.576047897338867\n",
      "Epoch 997: perda treino: 25.576007843017578\n",
      "Epoch 998: perda treino: 25.57596778869629\n",
      "Epoch 999: perda treino: 25.575931549072266\n",
      "Teste - perda depois do treinamento 27.65269660949707\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
